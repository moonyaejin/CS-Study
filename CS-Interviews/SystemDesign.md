## 📋 질문 목록
1. [분산 시스템의 CAP 정리(CAP Theorem)란?](#1-분산-시스템의-cap-정리cap-theorem가-무엇이고-세-가지-속성에-대해-설명해주세요)
2. [Rate Limiting(속도 제한)이란 무엇이고, 왜 필요한가요?](#2-rate-limiting속도-제한이란-무엇이고-왜-필요한가요)

---

## 1. 분산 시스템의 CAP 정리(CAP Theorem)가 무엇이고, 세 가지 속성에 대해 설명해주세요.
> 출처: 개발자: 데일리 CS 역량 강화 챌린지 (2025.12.04)

**답변**

CAP 정리는 분산 시스템에서 **Consistency(일관성), Availability(가용성), Partition Tolerance(분할 내성) 세 가지 속성을 동시에 모두 만족할 수 없고, 최대 두 가지만 보장할 수 있다**는 이론입니다.

**세 가지 속성**

- **Consistency (일관성)**: 모든 노드가 같은 시점에 동일한 데이터를 보여줍니다. 어떤 노드에 요청하든 가장 최신의 데이터를 반환합니다.

- **Availability (가용성)**: 모든 요청은 항상 응답을 받습니다. 일부 노드에 장애가 발생해도 시스템은 계속 동작합니다.

- **Partition Tolerance (분할 내성)**: 네트워크 분할(노드 간 통신 단절)이 발생해도 시스템이 계속 동작합니다.

실제 분산 환경에서 네트워크 분할은 피할 수 없기 때문에, 결국 **CP(일관성 + 분할 내성)** 또는 **AP(가용성 + 분할 내성)** 중 선택하게 됩니다.


## **예상 꼬리질문**

**Q1. 왜 세 가지 속성을 동시에 만족할 수 없나요?**

A. 네트워크 분할이 발생한 상황을 생각해보면 이해가 쉽습니다.

노드 A와 노드 B가 서로 통신이 끊긴 상태에서 클라이언트가 A에 데이터를 쓰고, 다른 클라이언트가 B에서 읽으려 한다면:

- **일관성을 선택하면**: B는 A와 동기화가 안 됐으니 응답을 거부해야 합니다 → 가용성 포기
- **가용성을 선택하면**: B는 예전 데이터라도 응답합니다 → 일관성 포기

네트워크 분할 상황에서 일관성과 가용성은 트레이드오프 관계가 되기 때문에 둘 중 하나를 선택해야 합니다.


**Q2. CP, AP 시스템의 실제 예시는 무엇인가요?**

A. **CP 시스템 (일관성 우선)**
- MongoDB (기본 설정): Primary 노드에서만 읽기/쓰기, 분할 시 일부 요청 거부
- HBase, Redis Cluster
- 사용 사례: 금융 거래, 재고 관리 등 데이터 정확성이 중요한 경우

**AP 시스템 (가용성 우선)**
- Cassandra: 분할 상황에서도 각 노드가 독립적으로 응답, 나중에 동기화
- DynamoDB, CouchDB
- 사용 사례: SNS 피드, 장바구니 등 일시적 불일치가 허용되는 경우

CA 시스템은 이론적으로 존재하지만, 네트워크 분할이 없다고 가정해야 해서 단일 노드 RDBMS 정도만 해당됩니다.


**Q3. CAP 정리의 한계점은 무엇인가요?**

A. CAP 정리는 개념을 이해하기엔 좋지만 실제 시스템 설계에 적용하기엔 너무 단순합니다.

첫째, **이분법적 선택이 아닙니다**. 실제로는 일관성의 수준(강한 일관성, 최종 일관성 등)을 조절할 수 있습니다.

둘째, **네트워크가 정상일 때를 고려하지 않습니다**. 분할이 발생하지 않은 평상시에 어떤 트레이드오프를 할지는 CAP으로 설명이 안 됩니다.

이런 한계를 보완한 것이 **PACELC 정리**입니다. "Partition 상황에서는 A와 C 중 선택하고, Else(정상 상황)에서는 Latency와 Consistency 중 선택한다"는 더 실용적인 프레임워크입니다.

---

## 2. Rate Limiting(속도 제한)이란 무엇이고, 왜 필요한가요?
> 출처: 개발자: 데일리 CS 역량 강화 챌린지 (2025.12.09)

**답변**

Rate Limiting은 **일정 시간 동안 허용되는 요청 수를 제한하는 기술**입니다. 예를 들어 "1분에 100번까지만 API 호출 가능"처럼 제한을 걸어둡니다.

**필요한 이유**
- **서버 보호**: 과도한 요청으로 인한 서버 과부하 방지
- **DDoS 공격 방어**: 악의적인 대량 요청 차단
- **공정한 자원 분배**: 특정 사용자가 자원을 독점하지 못하게 함
- **비용 관리**: 클라우드 환경에서 과도한 API 호출로 인한 비용 폭증 방지


## **예상 꼬리질문**

**Q1. Rate Limiting을 구현하는 알고리즘에는 어떤 것들이 있나요?**

A. 대표적으로 네 가지가 있습니다.

- **Fixed Window**: 고정된 시간 창(예: 1분)마다 카운터를 초기화합니다. 구현이 단순하지만 창 경계에서 트래픽이 몰리면 순간적으로 2배의 요청이 허용될 수 있습니다.

- **Sliding Window**: 현재 시점 기준으로 과거 일정 시간의 요청을 계산합니다. Fixed Window의 경계 문제를 해결하지만 구현이 복잡합니다.

- **Token Bucket**: 일정 속도로 토큰이 채워지고, 요청마다 토큰을 소비합니다. 버킷에 토큰이 있으면 버스트 트래픽도 허용됩니다.

- **Leaky Bucket**: 요청이 버킷에 쌓이고 일정 속도로 처리됩니다. 출력 속도가 일정해서 트래픽을 균일하게 만듭니다.


**Q2. Token Bucket과 Leaky Bucket의 차이는 무엇인가요?**

A. 둘 다 버킷 개념을 사용하지만 동작 방식이 다릅니다.

**Token Bucket**은 토큰이 쌓여 있으면 순간적인 버스트 트래픽을 허용합니다. 예를 들어 평소에 요청이 없다가 갑자기 10개의 요청이 와도, 토큰이 10개 이상 쌓여 있으면 모두 처리합니다.

**Leaky Bucket**은 버킷에서 나가는 속도가 항상 일정합니다. 요청이 아무리 많이 들어와도 처리 속도는 균일해서, 버스트 트래픽이 발생해도 뒤의 시스템은 안정적으로 유지됩니다.

버스트를 허용할지, 균일한 처리가 중요한지에 따라 선택합니다.


**Q3. Rate Limiting은 어디서 구현하나요?**

A. 여러 레이어에서 구현할 수 있습니다.

- **API Gateway**: 가장 일반적인 위치. AWS API Gateway, Kong, Nginx 등에서 제공
- **로드밸런서**: 인프라 레벨에서 초기 차단
- **애플리케이션 레벨**: 비즈니스 로직에 따른 세밀한 제어 (사용자별, 기능별)
- **Redis 같은 외부 저장소**: 분산 환경에서 여러 서버가 공유하는 카운터 관리

분산 환경에서는 각 서버가 독립적으로 카운트하면 제한이 제대로 안 걸리므로, Redis 같은 중앙 저장소로 카운터를 관리하는 게 일반적입니다.

---
